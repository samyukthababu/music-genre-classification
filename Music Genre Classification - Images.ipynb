{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the Dataset, performing transformations and splitting into Training, Validation and Test Set**"
      ],
      "metadata": {
        "id": "VQFdRpd6m6Nf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4OOIQEtmrGN"
      },
      "outputs": [],
      "source": [
        "# Import Statements\n",
        "\n",
        "from torch.utils import data\n",
        "import torch\n",
        "import torchvision as tv\n",
        "from torchvision import transforms\n",
        "import torch.utils.data as dt\n",
        "import datetime\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import random\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The location of the dataset in the Drive\n",
        "\n",
        "path = \"/content/drive/MyDrive/images_original\""
      ],
      "metadata": {
        "id": "F0FTRyA_oBNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we need to convert PIL images to Tensors and Resize all the images, we require 2 transformations\n",
        "# For this purpose, we can use \"transforms.Compose\", which takes a list of transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((180, 180))])\n",
        "dataset = tv.datasets.ImageFolder(path, transform)"
      ],
      "metadata": {
        "id": "N0i8W77voC3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Dataset into Training Set, Validation Set and Test Set\n",
        "# This can be done using torch.utils.data.random_split() method\n",
        "\n",
        "train_len = round((70/100) * len(dataset))\n",
        "val_len = round((20/100) * len(dataset))\n",
        "test_len = round((10/100) * len(dataset))\n",
        "\n",
        "# The Generator is set in order to reproduce the results\n",
        "\n",
        "train_data, val_data, test_data = dt.random_split(dataset, [train_len, val_len, test_len], generator=torch.Generator().manual_seed(42))"
      ],
      "metadata": {
        "id": "Q0e2vKcNoGCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We use the DataLoader to convert the training set into batches of images\n",
        "# The batch size is specified as 32\n",
        "# 2 processors have been used to batch the dataset in parallel\n",
        "# The training set will be shuffled for each epoch\n",
        "\n",
        "train_loader = dt.DataLoader(train_data, batch_size = 32, num_workers = 2, shuffle = True)\n",
        "val_loader = dt.DataLoader(val_data, batch_size = 32, num_workers = 2, shuffle = False)\n",
        "test_loader = dt.DataLoader(test_data, batch_size = 32, num_workers = 2, shuffle = False)"
      ],
      "metadata": {
        "id": "DbGI6plIoIoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the size of the images to ensure that the Resize Transformation worked\n",
        "\n",
        "itr = iter(train_loader)\n",
        "img, label = next(itr)\n",
        "print(img.size())\n",
        "print(label.size())\n",
        "print(\"Unique labels values = \", label.unique())"
      ],
      "metadata": {
        "id": "wfJI7IPQoLCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the Seed to ensure reproducibility\n",
        "\n",
        "seed = 123\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "iuv_Cw1yoNHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Loop for Network 1 and Network 2:**"
      ],
      "metadata": {
        "id": "MqShFjFQoQ8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop for Network 1 and 2\n",
        "\n",
        "def train1(epoch, train_loader, model, loss_function, optimiser):\n",
        "\n",
        "  # To visualise the loss and the accuracy for the training and validation set, TensorBoard is used\n",
        "  current_time = str(datetime.datetime.now().timestamp())\n",
        "  log_dir = 'logs/tensorboard/' + current_time\n",
        "\n",
        "  # The SummaryWriter Class is used to keep a log of the models created for the purpose of visualisation\n",
        "  writer = SummaryWriter(log_dir)\n",
        "\n",
        "  for epochs in range(epoch):\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for img, label in train_loader:\n",
        "\n",
        "      # Training the model\n",
        "      img = img.cuda()\n",
        "      label = label.cuda()\n",
        "      output = model(img)\n",
        "\n",
        "      # Finding out how well the model performed using the Loss Function\n",
        "      # We will use Cross Entropy loss as we dealing with multiple classes\n",
        "      loss = loss_function(output, label)\n",
        "\n",
        "      # Finding the best parameters to minimise the Loss function\n",
        "      # We will be using the Adam optimiser and Backpropagation\n",
        "      # Adam will move towards the Global Minimum\n",
        "      # Backpropagation will update the weights\n",
        "\n",
        "      optimiser.zero_grad()\n",
        "      loss.backward()\n",
        "      optimiser.step()\n",
        "\n",
        "      # Computing the Average loss at each epoch\n",
        "      # This will give us a smoother curve for visualisation\n",
        "      epoch_loss = 0.9 * epoch_loss + 0.1 * loss.item()\n",
        "\n",
        "    print(\"Traning Loss at Epoch {}: {:.4f}\".format(epochs, epoch_loss))\n",
        "\n",
        "    # Traning and Validation accuracy for each epoch\n",
        "    train_accuracy = evaluation_function1(train_loader, model)\n",
        "    validation_accuracy = evaluation_function1(val_loader, model)\n",
        "\n",
        "    # Giving the Training and Validation Accuracy to the SummaryWriter class to visualise in TensorBoard\n",
        "    writer.add_scalar(\"Loss over Epoch\", epoch_loss, epochs)\n",
        "    writer.add_scalars(\"Accuracy\", {\"Training Accuracy\": train_accuracy, \"Validation Accuracy\": validation_accuracy}, epochs)\n",
        "\n",
        "  writer.close()\n",
        "  return model"
      ],
      "metadata": {
        "id": "_B8tzNcwoQQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Function for Network 1 and 2:**"
      ],
      "metadata": {
        "id": "h-ddvrBooZtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This evaluation function is used for Networks 1 and 2\n",
        "# Evaluating the perfromance of the network on the Validation set\n",
        "\n",
        "def evaluation_function1(loader, model):\n",
        "  total = 0\n",
        "  for img, label in loader:\n",
        "\n",
        "    # The data (image, label) are unseen by the model and so is again passed to the GPU\n",
        "    # We do not pass the model however again\n",
        "    img = img.cuda()\n",
        "    label = label.cuda()\n",
        "\n",
        "    # Each image will have 10 probabilities (1 for each class from index 0 - 9)\n",
        "    output = model(img)\n",
        "\n",
        "    # Each index will indicate the class 0 - 9, which will be compared with the label\n",
        "    _, prediction = torch.max(output, dim = 1)\n",
        "    total += (prediction == label).sum()\n",
        "\n",
        "  return (total/len(loader.dataset)).item()"
      ],
      "metadata": {
        "id": "gtmtQJd_oXQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Network 1:**"
      ],
      "metadata": {
        "id": "D_obyqBZoe8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Network with 2 Hidden Layers\n",
        "\n",
        "input_size = 3 * 180 * 180\n",
        "hidden_size1 = 512\n",
        "hidden_size2 = 512\n",
        "output_size = 10\n",
        "\n",
        "class Net1(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, in_features, out_features) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "    # Input Image size is (32, 3, 180, 180)\n",
        "    self.hidden_layer1 = torch.nn.Linear(in_features, hidden_size1)\n",
        "\n",
        "    # Input Image size is (32, 3, 512, 512)\n",
        "    self.hidden_layer2 = torch.nn.Linear(hidden_size1, hidden_size2)\n",
        "\n",
        "    # Input Image size is (32, 3, 512, 512)\n",
        "    self.output_layer = torch.nn.Linear(hidden_size2, out_features)\n",
        "\n",
        "    # ReLu Layer (non-linear activation function)\n",
        "    self.relu_layer = torch.nn.ReLU()\n",
        "\n",
        "  def forward(self, image):\n",
        "\n",
        "    # Input Layer\n",
        "    image = image.flatten(start_dim = 1)\n",
        "\n",
        "    # Hidden Layer 1\n",
        "    image = self.hidden_layer1(image)\n",
        "    image = self.relu_layer(image)\n",
        "\n",
        "    # Hidden Layer 2\n",
        "    image = self.hidden_layer2(image)\n",
        "    image = self.relu_layer(image)\n",
        "\n",
        "    # Output Layer\n",
        "    image = self.output_layer(image)\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "9EmRt4Vjof6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Net1(3 * 180 * 180, 10)\n",
        "model1 = model1.cuda()\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimiser = torch.optim.Adam(model1.parameters())"
      ],
      "metadata": {
        "id": "jp9pgZApojnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading TensorBoard on the notebook\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "xwjdOBDPooLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model on 50 epochs\n",
        "!rm -rf logs\n",
        "model1 = train1(50, train_loader, model1, loss_function, optimiser)\n",
        "%tensorboard --logdir logs/tensorboard"
      ],
      "metadata": {
        "id": "TT_7USXzooya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model run on 50 Epochs\n",
        "test_accuracy1 = evaluation_function1(test_loader, model1)\n",
        "print(test_accuracy1)"
      ],
      "metadata": {
        "id": "dnrhIkSnot-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model on 100 epochs\n",
        "!rm -rf logs\n",
        "model1 = train1(100, train_loader, model1, loss_function, optimiser)\n",
        "%tensorboard --logdir logs/tensorboard"
      ],
      "metadata": {
        "id": "R3OC8St5ow4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model run on 100 Epochs\n",
        "test_accuracy1 = evaluation_function1(test_loader, model1)\n",
        "print(test_accuracy1)"
      ],
      "metadata": {
        "id": "6CN1jjDjo2qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Network 2:**"
      ],
      "metadata": {
        "id": "FR8jXhxvpALE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Convolutional Neural Network\n",
        "\n",
        "class Net2(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # Input Image size is (32, 3, 180, 180)\n",
        "    self.conv_layer1 = torch.nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3)\n",
        "\n",
        "    # Input Image size is (32, 32, 178, 178)\n",
        "    self.conv_layer2 = torch.nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3)\n",
        "\n",
        "    # Input Image size is (32, 32, 176, 176)\n",
        "    self.max_pool_layer1 = torch.nn.MaxPool2d(kernel_size = (2,2))\n",
        "\n",
        "    # Input Image size is (32, 32, 88, 88)\n",
        "    self.conv_layer3 = torch.nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3)\n",
        "\n",
        "    # Input Image size is (32, 64, 86, 86)\n",
        "    self.conv_layer4 = torch.nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3)\n",
        "\n",
        "    # Input Image size is (32, 64, 84, 84)\n",
        "    self.max_pool_layer2 = torch.nn.MaxPool2d(kernel_size = (2,2))\n",
        "\n",
        "    # Input Image size is (32, 64, 42, 42)\n",
        "    self.flatten = torch.nn.Flatten()\n",
        "\n",
        "    # Input Image size is (32, 64 * 42 * 42)\n",
        "    self.fc_layer1 = torch.nn.Linear(in_features = 64 * 42 * 42, out_features = 256)\n",
        "    self.fc_layer2 = torch.nn.Linear(in_features = 256, out_features = 10)\n",
        "\n",
        "    # ReLu Layer (non-linear activation function)\n",
        "    self.relu_layer = torch.nn.ReLU()\n",
        "\n",
        "  def forward(self, image):\n",
        "\n",
        "    # 2 Convolution Layers followed by ReLU (Non-linear Activation Function)\n",
        "    image = self.conv_layer1(image)\n",
        "    image = self.relu_layer(image)\n",
        "    image = self.conv_layer2(image)\n",
        "    image = self.relu_layer(image)\n",
        "    # Max Pooling Layer 1\n",
        "    image = self.max_pool_layer1(image)\n",
        "\n",
        "    # 2 Convolution Layers followed by ReLU (Non-linear Activation Function)\n",
        "    image = self.conv_layer3(image)\n",
        "    image = self.relu_layer(image)\n",
        "    image = self.conv_layer4(image)\n",
        "    image = self.relu_layer(image)\n",
        "    # Max Pooling Layer 2\n",
        "    image = self.max_pool_layer1(image)\n",
        "\n",
        "    # Flattening the image before passing it to the Fully Connected Network\n",
        "    image = self.flatten(image)\n",
        "\n",
        "    # Fully Connected Layer 1\n",
        "    image = self.fc_layer1(image)\n",
        "    image = self.relu_layer(image)\n",
        "\n",
        "    # Fully Connected Layer 2 (Predicts the output)\n",
        "    image = self.fc_layer2(image)\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "D3bjnS5BpCDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Net2()\n",
        "model2 = model2.cuda()\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimiser = torch.optim.Adam(model2.parameters())"
      ],
      "metadata": {
        "id": "vx0qnObupJa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model on 50 epochs\n",
        "!rm -rf logs\n",
        "model2 = train1(50, train_loader, model2, loss_function, optimiser)\n",
        "%tensorboard --logdir logs/tensorboard"
      ],
      "metadata": {
        "id": "t3YyBmdJpNbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model run on 50 Epochs\n",
        "test_accuracy2 = evaluation_function1(test_loader, model2)\n",
        "print(test_accuracy2)"
      ],
      "metadata": {
        "id": "dS-dhMPTpSw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model on 100 epochs\n",
        "!rm -rf logs\n",
        "model2 = train1(100, train_loader, model2, loss_function, optimiser)\n",
        "%tensorboard --logdir logs/tensorboard"
      ],
      "metadata": {
        "id": "mpP81DPJpVcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model run on 100 Epochs\n",
        "test_accuracy2 = evaluation_function1(test_loader, model2)\n",
        "print(test_accuracy2)"
      ],
      "metadata": {
        "id": "JbJOuRDTpZYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Loop for Network 3 and 4:**"
      ],
      "metadata": {
        "id": "9WfY4bp1pcey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop for Network 3 and 4\n",
        "\n",
        "def train2(epoch, train_loader, model, loss_function, optimiser):\n",
        "\n",
        "  # To visualise the loss and the accuracy for the training and validation set, TensorBoard is used\n",
        "  current_time = str(datetime.datetime.now().timestamp())\n",
        "  log_dir = 'logs/tensorboard/' + current_time\n",
        "\n",
        "  # The SummaryWriter Class is used to keep a log of the models created for the purpose of visualisation\n",
        "  writer = SummaryWriter(log_dir)\n",
        "\n",
        "  for epochs in range(epoch):\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    # This command is called to allow the model to compute the running mean and average\n",
        "    # This is a book keeping step and does not have any effect on the training\n",
        "    model.train()\n",
        "\n",
        "    for img, label in train_loader:\n",
        "\n",
        "      # Training the model\n",
        "      img = img.cuda()\n",
        "      label = label.cuda()\n",
        "      output = model(img)\n",
        "\n",
        "      # Finding out how well the model performed using the Loss Function\n",
        "      # We will use Cross Entropy loss as we dealing with multiple classes\n",
        "      loss = loss_function(output, label)\n",
        "\n",
        "      # Finding the best parameters to minimise the Loss function\n",
        "      # We will be using Adam/RMSprop and Backpropagation\n",
        "      # Adam/RMSprop will move towards the Global Minimum\n",
        "      # Backpropagation will update the weights\n",
        "      optimiser.zero_grad()\n",
        "      loss.backward()\n",
        "      optimiser.step()\n",
        "\n",
        "      # Computing the Average loss at each epoch\n",
        "      # This will give us a smoother curve for visualisation\n",
        "      epoch_loss = 0.9 * epoch_loss + 0.1 * loss.item()\n",
        "\n",
        "    print(\"Traning Loss at Epoch {}: {:.4f}\".format(epochs, epoch_loss))\n",
        "\n",
        "    # Training and Validation accuracy for each epoch\n",
        "    train_accuracy = evaluation_function2(train_loader, model)\n",
        "    validation_accuracy = evaluation_function2(val_loader, model)\n",
        "\n",
        "    # Giving the Training and Validation Accuracy to the SummaryWriter class to visualise in TensorBoard\n",
        "    writer.add_scalar(\"Loss over Epoch\", epoch_loss, epochs)\n",
        "    writer.add_scalars(\"Accuracy\", {\"Training Accuracy\": train_accuracy, \"Validation Accuracy\": validation_accuracy}, epochs)\n",
        "\n",
        "  writer.close()\n",
        "  return model"
      ],
      "metadata": {
        "id": "e3LV_NE7ph_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation function for Network 3 and Network 4:**"
      ],
      "metadata": {
        "id": "Yq4E8X3Mppug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function for network 3 and 4\n",
        "\n",
        "def evaluate(batch, model):\n",
        "  total = 0\n",
        "  img, label = batch\n",
        "\n",
        "  # The data (image, label) are unseen by the model and so is again passed to the GPU\n",
        "  # We do not pass the model however again\n",
        "  img = img.cuda()\n",
        "  label = label.cuda()\n",
        "\n",
        "  # Each image will have 10 probabilities (1 for each class from index 0 - 9)\n",
        "  output = model(img)\n",
        "\n",
        "  # Each index will indicate the class 0 - 9, which will be compared with the label\n",
        "  _, prediction = torch.max(output, dim = 1)\n",
        "  total += (prediction == label).sum()\n",
        "\n",
        "  return (total/len(label)).item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluation_function2(loader, model):\n",
        "\n",
        "  # This command prevents running averages over the mean and variance\n",
        "  # It is used to evaluate the model\n",
        "  model.eval()\n",
        "\n",
        "  l_accuracy = []\n",
        "  for batch in loader:\n",
        "    l_accuracy.append(evaluate(batch, model))\n",
        "  l_accuracy = torch.tensor(l_accuracy)\n",
        "  accuracy = l_accuracy.mean()\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "LLghznyxpqjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Network 3:**"
      ],
      "metadata": {
        "id": "nVwuE4Nwpzdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Convolutional Neural Network\n",
        "\n",
        "class Net3(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # Input Image size is (32, 3, 180, 180)\n",
        "    self.conv_layer1 = torch.nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3)\n",
        "\n",
        "    # Input Image size is (32, 32, 178, 178)\n",
        "    self.conv_layer2 = torch.nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3)\n",
        "\n",
        "    # Input Image size is (32, 32, 176, 176)\n",
        "    self.max_pool_layer1 = torch.nn.MaxPool2d(kernel_size = (2,2))\n",
        "\n",
        "    # Input Image size is (32, 32, 88, 88)\n",
        "    self.conv_layer3 = torch.nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3)\n",
        "\n",
        "    # Input Image size is (32, 64, 86, 86)\n",
        "    self.conv_layer4 = torch.nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3)\n",
        "\n",
        "    # Input Image size is (32, 64, 84, 84)\n",
        "    self.max_pool_layer2 = torch.nn.MaxPool2d(kernel_size = (2,2))\n",
        "\n",
        "    # Input Image size is (32, 64, 42, 42)\n",
        "    self.flatten = torch.nn.Flatten()\n",
        "\n",
        "    # Input Image size is (32, 64 * 42 * 42)\n",
        "    self.fc_layer1 = torch.nn.Linear(in_features = 64 * 42 * 42, out_features = 256)\n",
        "    self.fc_layer2 = torch.nn.Linear(in_features = 256, out_features = 10)\n",
        "\n",
        "    # ReLu Layer (non-linear activation function)\n",
        "    self.relu_layer = torch.nn.ReLU()\n",
        "\n",
        "    # Batch Normalisation Layer\n",
        "    # The parameter num_features represents the number of features channels from the previous Convolution Layer\n",
        "    self.batch_norm1 = torch.nn.BatchNorm2d(num_features = 32)\n",
        "    self.batch_norm2 = torch.nn.BatchNorm2d(num_features = 32)\n",
        "    self.batch_norm3 = torch.nn.BatchNorm2d(num_features = 64)\n",
        "    self.batch_norm4 = torch.nn.BatchNorm2d(num_features = 64)\n",
        "\n",
        "  def forward(self, image):\n",
        "\n",
        "    # 2 Convolution Layers and Batch Normalisation Layers followed by ReLU (Non-linear Activation Function)\n",
        "    image = self.conv_layer1(image)\n",
        "    image = self.batch_norm1(image)\n",
        "    image = self.relu_layer(image)\n",
        "    image = self.conv_layer2(image)\n",
        "    image = self.batch_norm2(image)\n",
        "    image = self.relu_layer(image)\n",
        "    # Max Pooling Layer 1\n",
        "    image = self.max_pool_layer1(image)\n",
        "\n",
        "    # 2 Convolution Layers and Batch Normalisation Layers followed by ReLU (Non-linear Activation Function)\n",
        "    image = self.conv_layer3(image)\n",
        "    image = self.batch_norm3(image)\n",
        "    image = self.relu_layer(image)\n",
        "    image = self.conv_layer4(image)\n",
        "    image = self.batch_norm4(image)\n",
        "    image = self.relu_layer(image)\n",
        "    # Max Pooling Layer 2\n",
        "    image = self.max_pool_layer1(image)\n",
        "\n",
        "    # Flattening the image before passing it to the Fully Connected Network\n",
        "    image = self.flatten(image)\n",
        "\n",
        "    # Fully Connected Layer 1\n",
        "    image = self.fc_layer1(image)\n",
        "    image = self.relu_layer(image)\n",
        "\n",
        "    # Fully Connected Layer 2 (Predicts the output)\n",
        "    image = self.fc_layer2(image)\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "pbLU13gRp0aC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = Net3()\n",
        "model3 = model3.cuda()\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimiser = torch.optim.Adam(model3.parameters())"
      ],
      "metadata": {
        "id": "EyVHFLVdp6AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model on 50 epochs\n",
        "!rm -rf logs\n",
        "model3 = train2(50, train_loader, model3, loss_function, optimiser)\n",
        "%tensorboard --logdir logs/tensorboard"
      ],
      "metadata": {
        "id": "CMbzhKhIp9_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model run on 50 Epochs\n",
        "test_accuracy3 = evaluation_function2(test_loader, model3)\n",
        "print(test_accuracy3)"
      ],
      "metadata": {
        "id": "0UCULhbxqBNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model on 100 epochs\n",
        "!rm -rf logs\n",
        "model3 = train2(100, train_loader, model3, loss_function, optimiser)\n",
        "%tensorboard --logdir logs/tensorboard"
      ],
      "metadata": {
        "id": "kxoYJ79bqDcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model run on 100 Epochs\n",
        "test_accuracy3 = evaluation_function2(test_loader, model3)\n",
        "print(test_accuracy3)"
      ],
      "metadata": {
        "id": "GSoY0AbtqIbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Network 4:**\n",
        "This network has the same architecture as Network 3, but uses the RMSProp Optimiser."
      ],
      "metadata": {
        "id": "mM8WbFmpqLUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = Net3()\n",
        "model4 = model4.cuda()\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimiser = torch.optim.RMSprop(model4.parameters(), lr = 0.001, momentum = 0.9)"
      ],
      "metadata": {
        "id": "OT2UZI0lqNbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model on 50 epochs\n",
        "!rm -rf logs\n",
        "model4 = train2(50, train_loader, model4, loss_function, optimiser)\n",
        "%tensorboard --logdir logs/tensorboard"
      ],
      "metadata": {
        "id": "rBoOYS4IqSgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model run on 50 Epochs\n",
        "test_accuracy4 = evaluation_function2(test_loader, model4)\n",
        "print(test_accuracy4)"
      ],
      "metadata": {
        "id": "vLyRHLczqcuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model on 100 epochs\n",
        "!rm -rf logs\n",
        "model4 = train2(100, train_loader, model4, loss_function, optimiser)\n",
        "%tensorboard --logdir logs/tensorboard"
      ],
      "metadata": {
        "id": "sxdQ5l3uqZMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model run on 100 Epochs\n",
        "test_accuracy4 = evaluation_function2(test_loader, model4)\n",
        "print(test_accuracy4)"
      ],
      "metadata": {
        "id": "pS96TycEqkeZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}